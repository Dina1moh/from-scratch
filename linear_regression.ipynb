{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvxH2us8LE18"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class simple_linear_regression():\n",
        "    def __init__(self):\n",
        "        self.w = np.random.randn(1)\n",
        "        self.b = np.random.randn(1)\n",
        "\n",
        "    def loss(self,x,y_targ):\n",
        "      m=x.shape[0]\n",
        "      f_ln=np.dot(self.w,x.T) + self.b\n",
        "      total_loss=np.sum(np.square(y_targ-f_ln))\n",
        "      avre_total_loss=total_loss/(2*m)\n",
        "      return avre_total_loss,f_ln\n",
        "    def grident_descent(self,lr,y_targ,x):\n",
        "      loss_value,f_ln=self.loss(x,y_targ)\n",
        "\n",
        "      m=x.shape[0]\n",
        "      dw = -(1 / m) * np.dot(x.T, (y_targ - f_ln))\n",
        "      db = -(1 / m) * np.sum(y_targ - f_ln)\n",
        "      self.w -=lr*dw\n",
        "      self.b -=lr*db\n",
        "\n",
        "      return loss_value\n",
        "    def fit (self,x,y_targ,lr,epochs):\n",
        "      for i in range(epochs):\n",
        "        loss_value=self.grident_descent(lr,y_targ,x)\n",
        "        if i%100==0:\n",
        "          print(f\"epoch {i},loss {loss_value}\\n\")\n",
        "          print(f\"wight {self.w},bais{self.b}\")\n",
        "    def pridection(x,y)\n",
        "        return np.dot(self.w,x.T) + self.b\n",
        "\n",
        "\n",
        "\n",
        "x = np.array([[1], [2], [3]])\n",
        "y = np.array([1, 2, 3])\n",
        "model = simple_linear_regression()\n",
        "model.fit(x, y, lr=0.01, epochs=1000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc6M1NZzLGun",
        "outputId": "b8361520-b724-41fd-fa3f-84eea84a77b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0,loss 0.252430689088118\n",
            "\n",
            "wight [0.18386829],bais[1.43107813]\n",
            "epoch 100,loss 0.12716604634521117\n",
            "\n",
            "wight [0.41445772],bais[1.32966475]\n",
            "epoch 200,loss 0.09997779150823975\n",
            "\n",
            "wight [0.48126943],bais[1.17919183]\n",
            "epoch 300,loss 0.0786030382793947\n",
            "\n",
            "wight [0.54005246],bais[1.04556886]\n",
            "epoch 400,loss 0.06179810070047325\n",
            "\n",
            "wight [0.59217279],bais[0.9270871]\n",
            "epoch 500,loss 0.04858597496716563\n",
            "\n",
            "wight [0.63838695],bais[0.82203145]\n",
            "epoch 600,loss 0.03819853582477449\n",
            "\n",
            "wight [0.67936422],bais[0.7288805]\n",
            "epoch 700,loss 0.030031879367300073\n",
            "\n",
            "wight [0.71569802],bais[0.64628523]\n",
            "epoch 800,loss 0.023611213332085598\n",
            "\n",
            "wight [0.74791455],bais[0.57304948]\n",
            "epoch 900,loss 0.01856325367436953\n",
            "\n",
            "wight [0.77648037],bais[0.50811267]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class simple_linear_regression():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w = np.random.randn(1)\n",
        "        self.b = np.random.randn(1)\n",
        "\n",
        "    def loss(self ,y_pred, y_targ):\n",
        "      m = x.shape[0]\n",
        "      total_loss=np.sum(np.square(y_targ - y_pred))\n",
        "      avre_total_loss=total_loss/(2 * m)\n",
        "      return avre_total_loss\n",
        "\n",
        "    def gradient_descent(self,lr,y_targ,x):\n",
        "      f_ln = self.predict(x,y_targ)\n",
        "      loss_value = self.loss(f_ln, y_targ)\n",
        "      m = x.shape[0]\n",
        "      dw = -(1 / m) * np.dot(x.T, (y_targ - f_ln))\n",
        "      db = -(1 / m) * np.sum(y_targ - f_ln)\n",
        "      self.w -=lr * dw\n",
        "      self.b -=lr * db\n",
        "      return loss_value\n",
        "\n",
        "    def fit (self,x,y_targ,lr,epochs):\n",
        "      for i in range(epochs):\n",
        "        loss_value=self.gradient_descent(lr, y_targ,x)\n",
        "        if i%100==0:\n",
        "          print(f\"epoch {i},loss {loss_value}\\n\")\n",
        "          print(f\"wight {self.w},bais{self.b}\")\n",
        "\n",
        "    def predict(self,x,y_targ):\n",
        "      return np.dot(self.w, x.T) + self.b\n",
        "\n",
        "x = np.array([[1], [2], [3]])\n",
        "y = np.array([1, 2, 3])\n",
        "\n",
        "model = simple_linear_regression()\n",
        "\n",
        "model.fit(x, y, lr=0.01, epochs=1000)"
      ],
      "metadata": {
        "id": "plOImZxLLKK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96a08c8-48b2-4e06-937e-5bf8e88db398"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0,loss 0.011936547576132587\n",
            "\n",
            "wight [1.18736455],bais[-0.36761175]\n",
            "epoch 100,loss 0.008037228654477578\n",
            "\n",
            "wight [1.14714729],bais[-0.33430647]\n",
            "epoch 200,loss 0.0063188943533895306\n",
            "\n",
            "wight [1.13040972],bais[-0.29645131]\n",
            "epoch 300,loss 0.004967946253749785\n",
            "\n",
            "wight [1.11563174],bais[-0.26285813]\n",
            "epoch 400,loss 0.003905824120595714\n",
            "\n",
            "wight [1.10252859],bais[-0.23307158]\n",
            "epoch 500,loss 0.003070778402546623\n",
            "\n",
            "wight [1.09091025],bais[-0.20666037]\n",
            "epoch 600,loss 0.0024142612945174283\n",
            "\n",
            "wight [1.08060849],bais[-0.18324204]\n",
            "epoch 700,loss 0.0018981042700349914\n",
            "\n",
            "wight [1.07147409],bais[-0.16247742]\n",
            "epoch 800,loss 0.0014922990432339296\n",
            "\n",
            "wight [1.06337479],bais[-0.1440658]\n",
            "epoch 900,loss 0.0011732529501110277\n",
            "\n",
            "wight [1.05619329],bais[-0.12774056]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UjKqcVWTUWUB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}